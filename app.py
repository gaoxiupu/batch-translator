import streamlit as st
import pandas as pd
import os
import time
import io
import zipfile
import extra_streamlit_components as stx
from utils.translator import translate_text

# Page Configuration
st.set_page_config(
    page_title="Batch-LLM-Translator",
    page_icon="ðŸŒ",
    layout="wide"
)

# Initialize Session State
if 'is_processing' not in st.session_state:
    st.session_state.is_processing = False
if 'processed_files' not in st.session_state:
    st.session_state.processed_files = [] # List of tuples: (filename, dataframe)

def main():
    show_translator_app()

def show_translator_app():
    st.title("ðŸŒ Batch-LLM-Translator")
    
    # Initialize Cookie Manager
    cookie_manager = stx.CookieManager()
    
    # --- Sidebar Configuration ---
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½® (Settings)")
        
        # New model options
        model_option = st.selectbox(
            "1. é€‰æ‹©æ¨¡åž‹ (Model)",
            ("gemini-2.5-flash", "deepseek v3.2", "glm-4.6", "kimi-k2")
        )
        
        # Retrieve API Key from cookie if available
        cookie_api_key = cookie_manager.get(cookie="api_key_v1")
        
        # Initialize session state for API Key if not present
        if 'api_key_input' not in st.session_state:
            st.session_state.api_key_input = cookie_api_key if cookie_api_key else ""

        api_key = st.text_input(
            "2. API Key",
            value=st.session_state.api_key_input,
            type="password",
            help="è¾“å…¥å¯¹åº”æ¨¡åž‹çš„ API Keyã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨ä¿å­˜åˆ°æµè§ˆå™¨ Cookies ä¸­ã€‚",
            key="api_key_widget"
        )
        
        # Save API Key to cookie when changed
        if api_key != st.session_state.api_key_input:
            st.session_state.api_key_input = api_key
            cookie_manager.set("api_key_v1", api_key, key="set_api_key")
        
        # Supported Languages List
        LANGUAGES = [
            "Simplified Chinese", "Traditional Chinese", "English", "Japanese", "Korean",
            "Vietnamese", "Thai", "Indonesian", "Malay", "Filipino", "Khmer", "Lao", "Burmese",
            "French", "German", "Spanish", "Italian", "Portuguese", "Russian",
            "Ukrainian", "Polish", "Dutch", "Turkish", "Greek", "Hebrew", "Arabic", "Hindi",
            "Albanian", "Armenian", "Austrian German", "Basque", "Belarusian", "Bosnian", "Bulgarian",
            "Catalan", "Croatian", "Czech", "Danish", "Estonian", "Finnish", "Galician", "Georgian",
            "Hungarian", "Icelandic", "Irish", "Latvian", "Lithuanian", "Luxembourgish", "Macedonian",
            "Maltese", "Norwegian", "Romanian", "Serbian", "Slovak", "Slovenian", "Swedish", "Welsh"
        ]
        
        target_lang = st.selectbox(
            "3. ç›®æ ‡è¯­è¨€ (Target Language)",
            options=LANGUAGES,
            index=0, # Defaults to Simplified Chinese
            help="Select the target language. You can type to search."
        )
        
        st.divider()
        st.info("â„¹ï¸ v1.3 by Factory Droid")

    # --- Main Area ---
    
    # File Uploader
    uploaded_files = st.file_uploader(
        "ðŸ“‚ ä¸Šä¼  CSV æ–‡ä»¶ (Upload CSV)", 
        type=['csv'], 
        accept_multiple_files=True,
        help="æ”¯æŒæ‹–æ‹½ä¸Šä¼ ã€‚è¯·ç¡®ä¿æ–‡ä»¶ç¬¬ä¸€åˆ—ä¸ºå¾…ç¿»è¯‘å†…å®¹ã€‚"
    )

    # File List & Action
    if uploaded_files:
        st.subheader("ðŸ“‹ å¾…å¤„ç†åˆ—è¡¨")
        
        # Display file stats
        file_data = []
        for f in uploaded_files:
            file_data.append({"Filename": f.name, "Size (KB)": round(f.size / 1024, 2)})
        st.table(pd.DataFrame(file_data))

        # Start Button
        start_btn = st.button("â–¶ï¸ å¼€å§‹ç¿»è¯‘ (Start Translation)", type="primary", disabled=st.session_state.is_processing)
        
        if start_btn:
            if not api_key:
                st.error("âŒ è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ API Keyï¼")
            elif not target_lang:
                st.error("âŒ è¯·è¾“å…¥ç›®æ ‡è¯­è¨€ï¼")
            else:
                # Clear previous results
                st.session_state.processed_files = []
                process_files(uploaded_files, model_option, api_key, target_lang)

    # --- Download Area ---
    if st.session_state.processed_files:
        st.divider()
        st.subheader("ðŸ“¥ ä¸‹è½½ç»“æžœ (Download Results)")
        
        # 1. Download as ZIP (if multiple files)
        if len(st.session_state.processed_files) > 1:
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                for fname, df_res in st.session_state.processed_files:
                    csv_data = df_res.to_csv(index=False).encode('utf-8')
                    zf.writestr(fname, csv_data)
            
            st.download_button(
                label="ðŸ“¦ æ‰“åŒ…ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ (.zip)",
                data=zip_buffer.getvalue(),
                file_name="translated_files.zip",
                mime="application/zip",
                type="primary"
            )
            st.caption("æˆ–è€…å•ç‹¬ä¸‹è½½ï¼š")

        # 2. Individual Downloads
        for fname, df_res in st.session_state.processed_files:
            csv_data = df_res.to_csv(index=False).encode('utf-8')
            st.download_button(
                label=f"ðŸ“„ ä¸‹è½½ {fname}",
                data=csv_data,
                file_name=fname,
                mime="text/csv"
            )

def process_files(files, model, key, lang):
    st.session_state.is_processing = True
    
    # Progress placeholder
    progress_bar = st.progress(0)
    status_text = st.empty()
    console = st.expander("ðŸ“Ÿ è¿è¡Œæ—¥å¿— (Console Log)", expanded=True)
    
    total_files = len(files)
    
    with console:
        st.write(f"[INFO] å¼€å§‹å¤„ç† {total_files} ä¸ªæ–‡ä»¶...")
        
        for idx, file in enumerate(files):
            file_name = file.name
            st.write(f"--- [FILE {idx+1}/{total_files}] {file_name} ---")
            status_text.text(f"æ­£åœ¨å¤„ç†: {file_name}...")
            
            try:
                # Reset file pointer
                file.seek(0)
                
                # Read CSV
                df = pd.read_csv(file)
                
                if df.empty:
                    st.warning(f"âš ï¸ æ–‡ä»¶ {file_name} ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
                    continue
                
                # Identify source column
                source_col = df.columns[0]
                new_col_name = f"Translated_{lang}"
                
                # Initialize new column
                df[new_col_name] = ""
                
                total_rows = len(df)
                
                # BATCH PROCESSING LOGIC
                # We process in chunks to balance Rate Limits vs Context Window.
                # A safe chunk size is 50 lines. 
                # This reduces API calls by 50x (e.g. 1000 lines -> 20 calls), satisfying "avoid too many requests".
                BATCH_SIZE = 50 
                
                for start_idx in range(0, total_rows, BATCH_SIZE):
                    end_idx = min(start_idx + BATCH_SIZE, total_rows)
                    batch_df = df.iloc[start_idx:end_idx]
                    
                    # Prepare batch text
                    # We use a special separator or just newlines.
                    # Warning: If source text contains newlines, this might be tricky.
                    # But assuming standard CSV content (titles, short descriptions).
                    batch_texts = batch_df[source_col].astype(str).tolist()
                    
                    # Remove internal newlines in cells to avoid confusion? 
                    # Or we just hope the LLM is smart enough.
                    # Safer: Replace internal newlines with a placeholder if needed, but for now simple join.
                    batch_input = "\n".join([t.replace('\n', ' ') for t in batch_texts])
                    
                    st.write(f"Processing batch {start_idx}-{end_idx} ({len(batch_texts)} lines)...")
                    
                    # Call API
                    translation_block = translate_text(batch_input, lang, model, key)
                    
                    # Process Output
                    if translation_block.startswith("[Error"):
                        # If error, fill batch with error message
                        translated_lines = [translation_block] * len(batch_texts)
                    else:
                        translated_lines = translation_block.strip().split('\n')
                        
                        # Handle mismatch: 
                        # If LLM returns fewer lines, we might have lost data.
                        # If more lines, maybe it added extra.
                        if len(translated_lines) != len(batch_texts):
                            st.warning(f"Batch mismatch: Input {len(batch_texts)} lines, Output {len(translated_lines)} lines. Attempting to align.")
                            # Pad or truncate
                            if len(translated_lines) < len(batch_texts):
                                translated_lines += [""] * (len(batch_texts) - len(translated_lines))
                            else:
                                translated_lines = translated_lines[:len(batch_texts)]
                    
                    # Update DataFrame
                    df.iloc[start_idx:end_idx, df.columns.get_loc(new_col_name)] = translated_lines
                    
                    # Update status
                    status_text.text(f"æ­£åœ¨å¤„ç†: {file_name} ({end_idx}/{total_rows})")
                    progress_bar.progress((idx + (end_idx / total_rows)) / total_files)
                    
                    # Rate limiting protection
                    time.sleep(1.0) # slightly longer sleep for batch
                
                # Store in session state instead of saving to disk
                base_name = os.path.splitext(file_name)[0]
                safe_lang = lang.replace(" ", "_")
                new_filename = f"{base_name}_{safe_lang}.csv"
                
                st.session_state.processed_files.append((new_filename, df))
                
                st.success(f"âœ… å®Œæˆå¤„ç†: {file_name}")
                
            except Exception as e:
                st.error(f"âŒ å¤„ç†æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {str(e)}")
            
            # Update main progress bar
            progress_bar.progress((idx + 1) / total_files)
            
    st.session_state.is_processing = False
    status_text.text("âœ¨ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼è¯·åœ¨ä¸‹æ–¹ä¸‹è½½ç»“æžœã€‚")
    st.balloons()

if __name__ == "__main__":
    main()
